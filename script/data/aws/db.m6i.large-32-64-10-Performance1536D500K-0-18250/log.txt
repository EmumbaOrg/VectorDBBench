DB Instance Type: db.m6i.large
DB Instance Provider: aws
DB enable_seqscan: on
db-label: run1-seqon
drop_old: True
load: True
search-serial: True
search-concurrent: True
case-type: Performance1536D500K
maintenance-work-mem: 4GB
max-parallel-workers: 2
ef-search: [10, 20, 40, 80, 120, 200, 400]
ef-construction: 64
m: 32
num-concurrency: 1,5,15,20,25,30,35,40,45,50,55,60,65,70
concurrency-duration: 30
run_count: 1
Current PostgreSQL configurations:
Raw query results: ['5min', '3902320kB', 'off', '4GB', '2', '2', '2', '6GB', '8', '1951160kB', 'zstd', '4MB']
checkpoint_timeout: 5min
effective_cache_size: 3902320kB
jit: off
maintenance_work_mem: 4GB
max_parallel_maintenance_workers: 2
max_parallel_workers: 2
max_parallel_workers_per_gather: 2
max_wal_size: 6GB
max_worker_processes: 8
shared_buffers: 1951160kB
wal_compression: zstd
work_mem: 4MB
Running command: vectordbbench pgvectorhnsw --user-name postgres --password Emumba123 --host aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com --db-name ann --drop-old --load --search-serial --search-concurrent --case-type Performance1536D500K --maintenance-work-mem 4GB --max-parallel-workers 2 --ef-construction 64 --m 32 --num-concurrency 1,5,15,20,25,30,35,40,45,50,55,60,65,70 --concurrency-duration 30 --ef-search 10
2024-09-01 19:21:00,500 | INFO |Task:
TaskConfig(db=<DB.PgVector: 'PgVector'>, db_config=PgVectorConfig(db_label='2024-09-01T19:21:00.488494', version='', note='', user_name=SecretStr('**********'), password=SecretStr('**********'), host='aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com', port=5432, db_name='ann'), db_case_config=PgVectorHNSWConfig(metric_type=None, create_index_before_load=False, create_index_after_load=True, m=32, ef_construction=64, ef_search=10, index=<IndexType.ES_HNSW: 'hnsw'>, maintenance_work_mem='4GB', max_parallel_workers=2), case_config=CaseConfig(case_id=<CaseType.Performance1536D500K: 10>, custom_case=None, k=100, concurrency_search_config=ConcurrencySearchConfig(num_concurrency=[1, 5, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70], concurrency_duration=30)), stages=['drop_old', 'load', 'search_serial', 'search_concurrent'])
 (cli.py:357)
2024-09-01 19:21:00,500 | DEBUG |tasks: [TaskConfig(db=<DB.PgVector: 'PgVector'>, db_config=PgVectorConfig(db_label='2024-09-01T19:21:00.488494', version='', note='', user_name=SecretStr('**********'), password=SecretStr('**********'), host='aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com', port=5432, db_name='ann'), db_case_config=PgVectorHNSWConfig(metric_type=None, create_index_before_load=False, create_index_after_load=True, m=32, ef_construction=64, ef_search=10, index=<IndexType.ES_HNSW: 'hnsw'>, maintenance_work_mem='4GB', max_parallel_workers=2), case_config=CaseConfig(case_id=<CaseType.Performance1536D500K: 10>, custom_case=None, k=100, concurrency_search_config=ConcurrencySearchConfig(num_concurrency=[1, 5, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70], concurrency_duration=30)), stages=['drop_old', 'load', 'search_serial', 'search_concurrent'])], task_label: None, dataset source: DatasetSource.S3 (interface.py:62)
2024-09-01 19:21:00,500 | INFO |generated uuid for the tasks: 4afb6c288f27418780e3711a27205dc6 (interface.py:66)
2024-09-01 19:21:00,561 | INFO | DB             | CaseType     Dataset               Filter | task_label (task_runner.py:340)
2024-09-01 19:21:00,561 | INFO | -----------    | ------------ -------------------- ------- | -------    (task_runner.py:340)
2024-09-01 19:21:00,561 | INFO | PgVector-2024-09-01T19:21:00.488494 | Performance  OpenAI-MEDIUM-500K      None | 4afb6c288f27418780e3711a27205dc6 (task_runner.py:340)
2024-09-01 19:21:00,561 | INFO |task submitted: id=4afb6c288f27418780e3711a27205dc6, 4afb6c288f27418780e3711a27205dc6, case number: 1 (interface.py:231)
2024-09-01 19:21:00,979 | INFO |[1/1] start case: {'label': <CaseLabel.Performance: 2>, 'dataset': {'data': {'name': 'OpenAI', 'size': 500000, 'dim': 1536, 'metric_type': <MetricType.COSINE: 'COSINE'>}}, 'db': 'PgVector-2024-09-01T19:21:00.488494'}, drop_old=True (interface.py:164)
2024-09-01 19:21:00,979 | INFO |Starting run (task_runner.py:100)
2024-09-01 19:21:01,053 | INFO |PgVector config values: {'host': 'aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com', 'port': 5432, 'dbname': 'ann', 'user': 'postgres', 'password': 'Emumba123'}
metric_type=<MetricType.COSINE: 'COSINE'> create_index_before_load=False create_index_after_load=True m=32 ef_construction=64 ef_search=10 index=<IndexType.ES_HNSW: 'hnsw'> maintenance_work_mem='4GB' max_parallel_workers=2 (pgvector.py:54)
2024-09-01 19:21:01,053 | INFO |PgVector client drop index : pgvector_index (pgvector.py:196)
2024-09-01 19:21:01,053 | DEBUG |DROP INDEX IF EXISTS "pgvector_index" (pgvector.py:201)
2024-09-01 19:21:01,514 | INFO |PgVector client drop table : pg_vector_collection (pgvector.py:172)
2024-09-01 19:21:01,660 | INFO |PgVector client create table : pg_vector_collection (pgvector.py:317)
2024-09-01 19:21:02,249 | INFO |Read the entire file into memory: test.parquet (dataset.py:229)
2024-09-01 19:21:02,297 | INFO |Read the entire file into memory: neighbors.parquet (dataset.py:229)
2024-09-01 19:21:02,320 | DEBUG |OpenAI: available train files ['shuffle_train.parquet'] (dataset.py:223)
2024-09-01 19:21:02,320 | INFO |Start performance case (task_runner.py:158)
2024-09-01 19:21:02,866 | DEBUG |SET "hnsw.ef_search" = "10"; (pgvector.py:137)
2024-09-01 19:21:02,866 | INFO |(SpawnProcess-1:1) Start inserting embeddings in batch 5000 (serial_runner.py:35)
2024-09-01 19:21:02,866 | INFO |Get iterator for shuffle_train.parquet (dataset.py:247)
2024-09-01 19:21:05,679 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:06,647 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:07,523 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:08,585 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:09,386 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:10,510 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:11,301 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:12,388 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:13,312 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:14,458 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:15,347 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:16,152 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:16,983 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:17,900 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:18,738 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:19,680 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:20,502 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:21,511 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:22,332 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:23,209 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:23,821 | INFO |(SpawnProcess-1:1) Loaded 100000 embeddings into VectorDB (serial_runner.py:59)
2024-09-01 19:21:24,298 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:25,085 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:26,187 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:27,012 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:28,023 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:28,869 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:29,841 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:30,886 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:31,803 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:32,726 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:33,603 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:34,492 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:35,452 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:36,336 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:37,233 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:38,052 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:39,078 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:40,212 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:41,116 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:42,348 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:43,659 | INFO |(SpawnProcess-1:1) Loaded 200000 embeddings into VectorDB (serial_runner.py:59)
2024-09-01 19:21:44,047 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:45,358 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:46,372 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:47,926 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:48,821 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:49,972 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:51,424 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:52,517 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:53,483 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:54,888 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:56,201 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:57,338 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:21:58,555 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:00,053 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:00,909 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:02,223 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:03,372 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:04,402 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:05,337 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:06,461 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:07,070 | INFO |(SpawnProcess-1:1) Loaded 300000 embeddings into VectorDB (serial_runner.py:59)
2024-09-01 19:22:07,510 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:08,416 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:09,710 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:10,651 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:11,518 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:12,491 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:13,689 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:14,773 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:16,306 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:17,858 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:18,930 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:19,830 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:21,026 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:21,863 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:23,040 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:24,241 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:25,195 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:26,163 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:27,018 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:28,306 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:28,989 | INFO |(SpawnProcess-1:1) Loaded 400000 embeddings into VectorDB (serial_runner.py:59)
2024-09-01 19:22:29,365 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:30,303 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:31,937 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:33,807 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:34,699 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:36,089 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:37,758 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:40,088 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:41,506 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:43,230 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:44,920 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:45,854 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:47,326 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:48,355 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:50,475 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:51,275 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:52,874 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:53,740 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:54,731 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:56,075 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-01 19:22:56,546 | INFO |(SpawnProcess-1:1) Loaded 500000 embeddings into VectorDB (serial_runner.py:59)
2024-09-01 19:22:56,653 | INFO |(SpawnProcess-1:1) Finish loading all dataset into VectorDB, dur=113.78714525299438 (serial_runner.py:61)
2024-09-01 19:22:57,353 | DEBUG |SET "hnsw.ef_search" = "10"; (pgvector.py:137)
2024-09-01 19:22:57,353 | INFO |PgVector post insert before optimize (pgvector.py:188)
2024-09-01 19:22:57,353 | INFO |PgVector client drop index : pgvector_index (pgvector.py:196)
2024-09-01 19:22:57,354 | DEBUG |DROP INDEX IF EXISTS "pgvector_index" (pgvector.py:201)
2024-09-01 19:22:57,355 | INFO |PgVector client create index : pgvector_index (pgvector.py:276)
2024-09-01 19:22:57,360 | INFO |PgVector parallel index creation parameters: [('2',), ('2',), ('4GB',)] (pgvector.py:271)
2024-09-01 19:22:57,360 | DEBUG |
            CREATE INDEX IF NOT EXISTS  "pgvector_index"  ON public. "pg_vector_collection"  
            USING  "hnsw"  (embedding  "vector_cosine_ops" )
             WITH ( "m" = "32", "ef_construction" = "64" ); (pgvector.py:308)
2024-09-01 19:37:56,813 | WARNING |VectorDB optimize timeout in 900 (task_runner.py:251)
2024-09-01 19:37:56,823 | WARNING |Failed to run performance case, reason = Performance case optimize timeout (task_runner.py:193)
Traceback (most recent call last):
  File "/home/ubuntu/vdbbenchmark/VectorDBBench/vectordb_bench/backend/task_runner.py", line 249, in _optimize
    return future.result(timeout=self.ca.optimize_timeout)[1]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 458, in result
    raise TimeoutError()
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/vdbbenchmark/VectorDBBench/vectordb_bench/backend/task_runner.py", line 165, in _run_perf_case
    m.build_dur = self._optimize()
                  ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/vdbbenchmark/VectorDBBench/vectordb_bench/backend/task_runner.py", line 254, in _optimize
    raise PerformanceTimeoutError("Performance case optimize timeout") from e
vectordb_bench.models.PerformanceTimeoutError: Performance case optimize timeout
2024-09-01 19:37:56,825 | WARNING |[1/1] case {'label': <CaseLabel.Performance: 2>, 'dataset': {'data': {'name': 'OpenAI', 'size': 500000, 'dim': 1536, 'metric_type': <MetricType.COSINE: 'COSINE'>}}, 'db': 'PgVector-2024-09-01T19:21:00.488494'} failed to run, reason=Performance case optimize timeout (interface.py:179)
2024-09-01 19:37:56,825 | INFO |Task summary: run_id=4afb6, task_label=4afb6c288f27418780e3711a27205dc6 (models.py:346)
2024-09-01 19:37:56,825 | INFO |DB       | db_label                      case                 label                            | load_dur    qps        latency(p99)    recall        max_load_count | label (models.py:346)
2024-09-01 19:37:56,825 | INFO |-------- | ----------------------------- -------------------- -------------------------------- | ----------- ---------- --------------- ------------- -------------- | ----- (models.py:346)
2024-09-01 19:37:56,825 | INFO |PgVector | 2024-09-01T19:21:00.488494    Performance1536D500K 4afb6c288f27418780e3711a27205dc6 | 0.0         0.0        0.0             0.0           0              | ?     (models.py:346)
2024-09-01 19:37:56,825 | INFO |write results to disk results/pgvector/hnsw/run1-seqon/aws/db.m6i.large-32-64-10-Performance1536D500K-0-18250/result_20240901_4afb6c288f27418780e3711a27205dc6_pgvector.json (models.py:204)
2024-09-01 19:37:56,826 | INFO |Success to finish task: label=4afb6c288f27418780e3711a27205dc6, run_id=4afb6c288f27418780e3711a27205dc6 (interface.py:203)
