DB Instance Type: db.m6i.large
DB Instance Provider: aws
DB enable_seqscan: on
db-label: run1-seqon
drop_old: True
load: True
search-serial: True
search-concurent: True
case-type: Performance1536D500K
maintenance-work-mem: 4GB
max-parallel-workers: 2
ef-search: [10, 20, 40, 80, 120, 200, 400]
ef-construction: 128
m: 16
num-concurrency: 1,5,15,20,25,30,35,40,45,50,55,60,65,70
concurrency-duration: 30
run_count: 1
Current PostgreSQL configurations:
Raw query results: ['5min', '3902320kB', 'off', '4GB', '2', '2', '2', '6GB', '8', '1951160kB', 'zstd', '4MB']
checkpoint_timeout: 5min
effective_cache_size: 3902320kB
jit: off
maintenance_work_mem: 4GB
max_parallel_maintenance_workers: 2
max_parallel_workers: 2
max_parallel_workers_per_gather: 2
max_wal_size: 6GB
max_worker_processes: 8
shared_buffers: 1951160kB
wal_compression: zstd
work_mem: 4MB
Running command: vectordbbench pgvectorhnsw --user-name postgres --password Emumba123 --host aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com --db-name ann --drop-old --load --search-serial --search-concurrent --case-type Performance1536D500K --maintenance-work-mem 4GB --max-parallel-workers 2 --ef-construction 128 --m 16 --num-concurrency 1,5,15,20,25,30,35,40,45,50,55,60,65,70 --concurrency-duration 30 --ef-search 10
2024-09-02 00:43:36,104 | INFO |Task:
TaskConfig(db=<DB.PgVector: 'PgVector'>, db_config=PgVectorConfig(db_label='2024-09-02T00:43:36.092033', version='', note='', user_name=SecretStr('**********'), password=SecretStr('**********'), host='aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com', port=5432, db_name='ann'), db_case_config=PgVectorHNSWConfig(metric_type=None, create_index_before_load=False, create_index_after_load=True, m=16, ef_construction=128, ef_search=10, index=<IndexType.ES_HNSW: 'hnsw'>, maintenance_work_mem='4GB', max_parallel_workers=2), case_config=CaseConfig(case_id=<CaseType.Performance1536D500K: 10>, custom_case=None, k=100, concurrency_search_config=ConcurrencySearchConfig(num_concurrency=[1, 5, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70], concurrency_duration=30)), stages=['drop_old', 'load', 'search_serial', 'search_concurrent'])
 (cli.py:357)
2024-09-02 00:43:36,104 | DEBUG |tasks: [TaskConfig(db=<DB.PgVector: 'PgVector'>, db_config=PgVectorConfig(db_label='2024-09-02T00:43:36.092033', version='', note='', user_name=SecretStr('**********'), password=SecretStr('**********'), host='aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com', port=5432, db_name='ann'), db_case_config=PgVectorHNSWConfig(metric_type=None, create_index_before_load=False, create_index_after_load=True, m=16, ef_construction=128, ef_search=10, index=<IndexType.ES_HNSW: 'hnsw'>, maintenance_work_mem='4GB', max_parallel_workers=2), case_config=CaseConfig(case_id=<CaseType.Performance1536D500K: 10>, custom_case=None, k=100, concurrency_search_config=ConcurrencySearchConfig(num_concurrency=[1, 5, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70], concurrency_duration=30)), stages=['drop_old', 'load', 'search_serial', 'search_concurrent'])], task_label: None, dataset source: DatasetSource.S3 (interface.py:62)
2024-09-02 00:43:36,104 | INFO |generated uuid for the tasks: 407eec2ab07e489486b703dce066eff4 (interface.py:66)
2024-09-02 00:43:36,165 | INFO | DB             | CaseType     Dataset               Filter | task_label (task_runner.py:340)
2024-09-02 00:43:36,165 | INFO | -----------    | ------------ -------------------- ------- | -------    (task_runner.py:340)
2024-09-02 00:43:36,165 | INFO | PgVector-2024-09-02T00:43:36.092033 | Performance  OpenAI-MEDIUM-500K      None | 407eec2ab07e489486b703dce066eff4 (task_runner.py:340)
2024-09-02 00:43:36,165 | INFO |task submitted: id=407eec2ab07e489486b703dce066eff4, 407eec2ab07e489486b703dce066eff4, case number: 1 (interface.py:231)
2024-09-02 00:43:36,583 | INFO |[1/1] start case: {'label': <CaseLabel.Performance: 2>, 'dataset': {'data': {'name': 'OpenAI', 'size': 500000, 'dim': 1536, 'metric_type': <MetricType.COSINE: 'COSINE'>}}, 'db': 'PgVector-2024-09-02T00:43:36.092033'}, drop_old=True (interface.py:164)
2024-09-02 00:43:36,583 | INFO |Starting run (task_runner.py:100)
2024-09-02 00:43:36,658 | INFO |PgVector config values: {'host': 'aws-rds-pg-postgres.cjegs2mait4g.us-east-1.rds.amazonaws.com', 'port': 5432, 'dbname': 'ann', 'user': 'postgres', 'password': 'Emumba123'}
metric_type=<MetricType.COSINE: 'COSINE'> create_index_before_load=False create_index_after_load=True m=16 ef_construction=128 ef_search=10 index=<IndexType.ES_HNSW: 'hnsw'> maintenance_work_mem='4GB' max_parallel_workers=2 (pgvector.py:54)
2024-09-02 00:43:36,658 | INFO |PgVector client drop index : pgvector_index (pgvector.py:196)
2024-09-02 00:43:36,658 | DEBUG |DROP INDEX IF EXISTS "pgvector_index" (pgvector.py:201)
2024-09-02 00:43:37,111 | INFO |PgVector client drop table : pg_vector_collection (pgvector.py:172)
2024-09-02 00:43:37,242 | INFO |PgVector client create table : pg_vector_collection (pgvector.py:317)
2024-09-02 00:43:37,843 | INFO |Read the entire file into memory: test.parquet (dataset.py:229)
2024-09-02 00:43:37,890 | INFO |Read the entire file into memory: neighbors.parquet (dataset.py:229)
2024-09-02 00:43:37,914 | DEBUG |OpenAI: available train files ['shuffle_train.parquet'] (dataset.py:223)
2024-09-02 00:43:37,914 | INFO |Start performance case (task_runner.py:158)
2024-09-02 00:43:38,454 | DEBUG |SET "hnsw.ef_search" = "10"; (pgvector.py:137)
2024-09-02 00:43:38,455 | INFO |(SpawnProcess-1:1) Start inserting embeddings in batch 5000 (serial_runner.py:35)
2024-09-02 00:43:38,455 | INFO |Get iterator for shuffle_train.parquet (dataset.py:247)
2024-09-02 00:43:40,787 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:41,759 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:42,629 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:43,736 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:44,573 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:45,614 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:46,447 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:47,499 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:48,421 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:49,325 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:50,206 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:51,111 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:51,992 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:52,964 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:53,770 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:54,674 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:55,468 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:56,502 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:57,340 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:58,189 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:43:58,836 | INFO |(SpawnProcess-1:1) Loaded 100000 embeddings into VectorDB (serial_runner.py:59)
2024-09-02 00:43:59,320 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:00,115 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:01,249 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:02,099 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:03,130 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:03,907 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:05,003 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:05,958 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:06,898 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:07,812 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:08,764 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:09,638 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:10,740 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:11,534 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:13,034 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:14,463 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:15,612 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:16,477 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:17,354 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:18,444 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:18,917 | INFO |(SpawnProcess-1:1) Loaded 200000 embeddings into VectorDB (serial_runner.py:59)
2024-09-02 00:44:19,294 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:20,406 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:21,198 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:22,327 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:23,156 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:24,135 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:25,021 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:25,979 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:26,920 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:27,812 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:28,690 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:29,669 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:30,578 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:31,448 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:32,285 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:33,252 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:34,038 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:34,904 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:36,171 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:36,985 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:37,568 | INFO |(SpawnProcess-1:1) Loaded 300000 embeddings into VectorDB (serial_runner.py:59)
2024-09-02 00:44:37,991 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:38,789 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:39,889 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:40,682 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:41,663 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:42,603 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:43,522 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:44,467 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:45,527 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:46,386 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:47,398 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:48,630 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:50,054 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:51,913 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:53,296 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:54,105 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:54,937 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:55,997 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:56,784 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:58,040 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:58,471 | INFO |(SpawnProcess-1:1) Loaded 400000 embeddings into VectorDB (serial_runner.py:59)
2024-09-02 00:44:58,846 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:44:59,882 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:00,789 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:01,778 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:02,664 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:03,888 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:04,799 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:05,678 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:06,594 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:07,558 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:08,344 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:09,364 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:10,220 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:11,249 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:12,262 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:13,109 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:14,226 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:15,008 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:16,137 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:16,922 | DEBUG |batch dataset size: 5000, 5000 (serial_runner.py:47)
2024-09-02 00:45:18,076 | INFO |(SpawnProcess-1:1) Loaded 500000 embeddings into VectorDB (serial_runner.py:59)
2024-09-02 00:45:18,185 | INFO |(SpawnProcess-1:1) Finish loading all dataset into VectorDB, dur=99.73022009599663 (serial_runner.py:61)
2024-09-02 00:45:18,886 | DEBUG |SET "hnsw.ef_search" = "10"; (pgvector.py:137)
2024-09-02 00:45:18,886 | INFO |PgVector post insert before optimize (pgvector.py:188)
2024-09-02 00:45:18,886 | INFO |PgVector client drop index : pgvector_index (pgvector.py:196)
2024-09-02 00:45:18,886 | DEBUG |DROP INDEX IF EXISTS "pgvector_index" (pgvector.py:201)
2024-09-02 00:45:18,889 | INFO |PgVector client create index : pgvector_index (pgvector.py:276)
2024-09-02 00:45:18,894 | INFO |PgVector parallel index creation parameters: [('2',), ('2',), ('4GB',)] (pgvector.py:271)
2024-09-02 00:45:18,894 | DEBUG |
            CREATE INDEX IF NOT EXISTS  "pgvector_index"  ON public. "pg_vector_collection"  
            USING  "hnsw"  (embedding  "vector_cosine_ops" )
             WITH ( "m" = "16", "ef_construction" = "128" ); (pgvector.py:308)
2024-09-02 01:00:18,340 | WARNING |VectorDB optimize timeout in 900 (task_runner.py:251)
2024-09-02 01:00:18,351 | WARNING |Failed to run performance case, reason = Performance case optimize timeout (task_runner.py:193)
Traceback (most recent call last):
  File "/home/ubuntu/vdbbenchmark/VectorDBBench/vectordb_bench/backend/task_runner.py", line 249, in _optimize
    return future.result(timeout=self.ca.optimize_timeout)[1]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 458, in result
    raise TimeoutError()
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/vdbbenchmark/VectorDBBench/vectordb_bench/backend/task_runner.py", line 165, in _run_perf_case
    m.build_dur = self._optimize()
                  ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/vdbbenchmark/VectorDBBench/vectordb_bench/backend/task_runner.py", line 254, in _optimize
    raise PerformanceTimeoutError("Performance case optimize timeout") from e
vectordb_bench.models.PerformanceTimeoutError: Performance case optimize timeout
2024-09-02 01:00:18,352 | WARNING |[1/1] case {'label': <CaseLabel.Performance: 2>, 'dataset': {'data': {'name': 'OpenAI', 'size': 500000, 'dim': 1536, 'metric_type': <MetricType.COSINE: 'COSINE'>}}, 'db': 'PgVector-2024-09-02T00:43:36.092033'} failed to run, reason=Performance case optimize timeout (interface.py:179)
2024-09-02 01:00:18,352 | INFO |Task summary: run_id=407ee, task_label=407eec2ab07e489486b703dce066eff4 (models.py:346)
2024-09-02 01:00:18,352 | INFO |DB       | db_label                      case                 label                            | load_dur    qps        latency(p99)    recall        max_load_count | label (models.py:346)
2024-09-02 01:00:18,352 | INFO |-------- | ----------------------------- -------------------- -------------------------------- | ----------- ---------- --------------- ------------- -------------- | ----- (models.py:346)
2024-09-02 01:00:18,352 | INFO |PgVector | 2024-09-02T00:43:36.092033    Performance1536D500K 407eec2ab07e489486b703dce066eff4 | 0.0         0.0        0.0             0.0           0              | ?     (models.py:346)
2024-09-02 01:00:18,352 | INFO |write results to disk results/pgvector/hnsw/run1-seqon/aws/db.m6i.large-16-128-10-Performance1536D500K-0-72589/result_20240902_407eec2ab07e489486b703dce066eff4_pgvector.json (models.py:204)
2024-09-02 01:00:18,353 | INFO |Success to finish task: label=407eec2ab07e489486b703dce066eff4, run_id=407eec2ab07e489486b703dce066eff4 (interface.py:203)
